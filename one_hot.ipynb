{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "one-hot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c4f211cd0b04209b651c3c9ee9cbf1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c2f0f5669ae40f0937500d17026de33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71351218fe20422f85ffa2767c60fe18",
              "IPY_MODEL_e1db0974c5fa49498d62cdc4e207f18a"
            ]
          }
        },
        "7c2f0f5669ae40f0937500d17026de33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71351218fe20422f85ffa2767c60fe18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3279a65562f047b7bd179fa625e6bb96",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd02ef67fa644e379a89a76b9fef0dc7"
          }
        },
        "e1db0974c5fa49498d62cdc4e207f18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2aaf459e6aa446c0ba21d35228ace243",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48762/? [00:33&lt;00:00, 1471.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29acab4147bb47bab73d8addaceeef7a"
          }
        },
        "3279a65562f047b7bd179fa625e6bb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd02ef67fa644e379a89a76b9fef0dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2aaf459e6aa446c0ba21d35228ace243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29acab4147bb47bab73d8addaceeef7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomTambe/omniglot-bcs/blob/master/one_hot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta4g8aPfKo1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52c2fa9f-7466-4b35-8bfb-0071c33f9c27"
      },
      "source": [
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/splines.py\n",
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/encoded.py\n",
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/weights/2-d/decoder.pth\n",
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/weights/2-d/encoder.pth\n",
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/data_background.mat"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-07 05:45:11--  https://github.com/SomTambe/omniglot-bcs/raw/master/splines.py\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/splines.py [following]\n",
            "--2020-07-07 05:45:12--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/splines.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4642 (4.5K) [text/plain]\n",
            "Saving to: ‘splines.py’\n",
            "\n",
            "\rsplines.py            0%[                    ]       0  --.-KB/s               \rsplines.py          100%[===================>]   4.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-07 05:45:12 (67.9 MB/s) - ‘splines.py’ saved [4642/4642]\n",
            "\n",
            "--2020-07-07 05:45:16--  https://github.com/SomTambe/omniglot-bcs/raw/master/encoded.py\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/encoded.py [following]\n",
            "--2020-07-07 05:45:16--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/encoded.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4214 (4.1K) [text/plain]\n",
            "Saving to: ‘encoded.py’\n",
            "\n",
            "encoded.py          100%[===================>]   4.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-07 05:45:17 (65.7 MB/s) - ‘encoded.py’ saved [4214/4214]\n",
            "\n",
            "--2020-07-07 05:45:20--  https://github.com/SomTambe/omniglot-bcs/raw/master/weights/2-d/decoder.pth\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/weights/2-d/decoder.pth [following]\n",
            "--2020-07-07 05:45:21--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/weights/2-d/decoder.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4217359 (4.0M) [application/octet-stream]\n",
            "Saving to: ‘decoder.pth’\n",
            "\n",
            "decoder.pth         100%[===================>]   4.02M  26.3MB/s    in 0.2s    \n",
            "\n",
            "2020-07-07 05:45:22 (26.3 MB/s) - ‘decoder.pth’ saved [4217359/4217359]\n",
            "\n",
            "--2020-07-07 05:45:26--  https://github.com/SomTambe/omniglot-bcs/raw/master/weights/2-d/encoder.pth\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/weights/2-d/encoder.pth [following]\n",
            "--2020-07-07 05:45:27--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/weights/2-d/encoder.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4225740 (4.0M) [application/octet-stream]\n",
            "Saving to: ‘encoder.pth’\n",
            "\n",
            "encoder.pth         100%[===================>]   4.03M  20.9MB/s    in 0.2s    \n",
            "\n",
            "2020-07-07 05:45:28 (20.9 MB/s) - ‘encoder.pth’ saved [4225740/4225740]\n",
            "\n",
            "--2020-07-07 05:45:32--  https://github.com/SomTambe/omniglot-bcs/raw/master/data_background.mat\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/data_background.mat [following]\n",
            "--2020-07-07 05:45:33--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/data_background.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21514095 (21M) [application/octet-stream]\n",
            "Saving to: ‘data_background.mat’\n",
            "\n",
            "data_background.mat 100%[===================>]  20.52M  50.9MB/s    in 0.4s    \n",
            "\n",
            "2020-07-07 05:45:34 (50.9 MB/s) - ‘data_background.mat’ saved [21514095/21514095]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F5qy4nhKmK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e18293db-caea-4e91-e879-0ad524e604eb"
      },
      "source": [
        "import splines\n",
        "import torch\n",
        "import glob\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import scipy\n",
        "from tqdm.notebook import tqdm\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import encoded\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul  7 05:45:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG63K2uxKmLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d1faa68-5c11-41c2-e9d2-ea524eb8e8d0"
      },
      "source": [
        "device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NntTEbdlKmLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "back_dict=splines.mat_to_dict()\n",
        "spline_prims=splines.spline_dict(back_dict)\n",
        "images=splines.dict_images()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb8gz-24KmLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99d6720d-098b-45a4-8b8b-c54dc3c17bff"
      },
      "source": [
        "dataset=encoded.OmniglotData(spline_prims)\n",
        "data_loader=DataLoader(dataset,batch_size=1,shuffle=False) # Using batchsize 1 to get single primitive at a time.\n",
        "# Create instances of models\n",
        "enc=encoded.encoder(latent_dim=2).to(device)\n",
        "dec=encoded.decoder(latent_dim=2).to(device)\n",
        "# Loading weights\n",
        "# enc.load_state_dict(torch.load('./weights/2-d/encoder.pth',map_location=torch.device('cpu')))\n",
        "# dec.load_state_dict(torch.load('./weights/2-d/decoder.pth',map_location=torch.device('cpu')))\n",
        "enc.load_state_dict(torch.load('encoder.pth'))\n",
        "dec.load_state_dict(torch.load('decoder.pth'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U889d28aKmLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "4c4f211cd0b04209b651c3c9ee9cbf1b",
            "7c2f0f5669ae40f0937500d17026de33",
            "71351218fe20422f85ffa2767c60fe18",
            "e1db0974c5fa49498d62cdc4e207f18a",
            "3279a65562f047b7bd179fa625e6bb96",
            "fd02ef67fa644e379a89a76b9fef0dc7",
            "2aaf459e6aa446c0ba21d35228ace243",
            "29acab4147bb47bab73d8addaceeef7a"
          ]
        },
        "outputId": "ffd2ce9e-2ce8-46f6-9def-2f17d78f996e"
      },
      "source": [
        "x_2d=[]\n",
        "y_2d=[]\n",
        "for i,data in tqdm(enumerate(data_loader)):\n",
        "    data=data.to(device)\n",
        "    mu,var=enc(data)\n",
        "    lat_var=encoded.gen_latent(mu,var).squeeze().detach().cpu().numpy()\n",
        "    x_2d.append(lat_var[0].item());y_2d.append(lat_var[1].item())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c4f211cd0b04209b651c3c9ee9cbf1b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n3JTfVOKmLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "983e73ed-e9c4-4a5b-c1e9-b14020d0e509"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import time\n",
        "start=time.time()\n",
        "X=np.concatenate((np.reshape(x_2d,(-1,1)),np.reshape(y_2d,(-1,1))),axis=1)\n",
        "kmeans = KMeans(300, random_state=0)\n",
        "labels = kmeans.fit(X).predict(X)\n",
        "print(\"%d\"%(time.time()-start))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te8zaFAwKmLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de3682f7-dd82-48c7-f735-d6177d9ecaf3"
      },
      "source": [
        "print(len(labels))\n",
        "print('max: ',np.max(labels,0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48762\n",
            "max:  299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozNNfNh5KmL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us now prepare the dataloader for the next model, for performing \n",
        "# supervised learning using the one-hot encoded vectors of a particular character.\n",
        "\n",
        "class OneHotDataset(IterableDataset):\n",
        "    \"\"\"\n",
        "    Iterable form dataset for providing one-hot encoded vectors for each character.\n",
        "    \n",
        "    Args:\n",
        "        data (dict): Just pass the spline_prims variable.\n",
        "        images (dict): Just pass the image dict.\n",
        "        labels (iterable type object): Labels for clustered data.\n",
        "        \n",
        "    Returns:\n",
        "        (Tensor) : One-hot encoded vector of length 300. (image,target)\n",
        "    \"\"\"\n",
        "    def __init__(self,data,images,labels,oh_len):\n",
        "        self.data=data\n",
        "        self.images=images\n",
        "        self.labels=labels\n",
        "        self.oh_len=oh_len\n",
        "    \n",
        "    def stream(self):\n",
        "        # spline_prims[lang][char][inst][0][primitive]\n",
        "        # images[lang][char][0]['image'][inst][0] -> (105,105) numpy ndarray\n",
        "        count=0\n",
        "        for lang in self.data:\n",
        "            for i,char in enumerate(self.data[lang]):\n",
        "                for j,inst in enumerate(char):\n",
        "                    vector=np.zeros((self.oh_len))\n",
        "                    for prim in inst[0]:\n",
        "                        # yield torch.tensor(prim.reshape(-1)).float()\n",
        "                        # yield torch.tensor(self.normalize(prim).reshape(-1)).float()\n",
        "                        idx=self.labels[count]\n",
        "                        # vector[idx]+=1.\n",
        "                        if vector[idx]==0:\n",
        "                            vector[idx]+=1.\n",
        "                        count+=1\n",
        "                    # yield [image,vector]\n",
        "                    img=self.images[lang][i][0]['image'][j][0]\n",
        "                    yield [torch.tensor(img).unsqueeze(0).float(),torch.tensor(vector).float()]\n",
        "                    \n",
        "    def __len__(self):\n",
        "        return int(19280) # Literally meaningless, hardcoded\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self.stream()\n",
        "        "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5vDui4kKmL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def which_cluster(vector):\n",
        "    \"\"\"\n",
        "    Dummy function to just give the indices of the clusters.\n",
        "    \n",
        "    Arg:\n",
        "        vector: You know what it is.\n",
        "    \"\"\"\n",
        "    vector=vector.reshape(-1)\n",
        "    which=[]\n",
        "    idx=0\n",
        "    for _ in vector:\n",
        "        # if vector[idx]==1:\n",
        "        #     which.append(idx)\n",
        "        # if vector[idx]>1:\n",
        "        #     which.append('{0},special'.format(idx))\n",
        "        if vector[idx]>0:\n",
        "            which.append(idx)\n",
        "        idx+=1\n",
        "    return which"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAB3pPVTKmMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=OneHotDataset(data=spline_prims,images=images,labels=labels,oh_len=300)\n",
        "data_loader=DataLoader(dataset,batch_size=1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJSrvMwKmMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "e1fda90a-4c1f-47f1-aa23-99c26d362a56"
      },
      "source": [
        "plot=96\n",
        "for k,i in enumerate(data_loader):\n",
        "#     print(i[0].shape,i[1].shape)\n",
        "    if plot==k:\n",
        "        print(which_cluster(i[1]))\n",
        "        plt.imshow(i[0].squeeze().detach().cpu().numpy(),cmap='gray')\n",
        "        break\n",
        "#     print(type(i[0]),type(i[1]))\n",
        "#     print(which_cluster(i[1]))\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22, 152, 172, 184, 236]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5fn/8fc9WSFhTQJkIcYk7LvEFawsLXUpUpSKVagKLZZq1W/VIvVSf+2lloI7fhWpFrFaNF9cQBSKYmlRMMoaFIIhECAQCUFCDEnI9vz+mEkahZBJZibnDOd+XVcuMmfOcucw+eSc5zznOWKMQSnlXC6rC1BKWUtDQCmH0xBQyuE0BJRyOA0BpRxOQ0AphwtICIjI5SKyS0R2i8h9gdiGUso/xN/9BEQkBPgK+BFQAHwO/NwYs8OvG1JK+UVoANZ5AbDbGLMHQEReByYATYZAbGysSUlJCUApSql6mzZtKjbGxH1/eiBCIBE40Oh1AXDh92cSkRnADIDk5GQ2btwYgFKUUvVEZN/pplvWMGiMWWiMyTDGZMTFnRJOSqk2EogQOAj0bPQ6yTNNKWVDgQiBz4FeInKuiIQD1wPLA7AdpZQf+L1NwBhTIyK3A/8EQoC/GWO+9Pd2lFL+EYiGQYwx7wPvB2LdSin/0h6DSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5XECeSqycrba2FmNMi5cTEUJCQgJQkToTDQHlVydPnuRvf/sbW7ZsafGyAwcO5Fe/+hXt2rULQGWqKRoCqkFr/np/X3V1NR988AFvv/12i5e9/PLLmTp1KpGRkYiIz7Uo72gIKADWrVvHihUrfA6Cqqoqtm/f3qplc3JyeOihh+jXrx9Tp04lOjrap1qUd1odAiLSE3gF6A4YYKEx5mkR6Qq8AaQA+cB1xphjvpeqAmnjxo3MmzfPL0cDrZWfn8/8+fMZOXIk11xzjYZAG/HlSKAGuNsYs1lEOgCbROQD4GZgjTFmjojcB9wHzPK9VOWruro63n//fbZu3XrKe5988omlAaCs0+oQMMYUAoWe778VkZ1AIjABGOWZbTGwFg0BW6itreWtt95i0aJFVpeibMQvbQIikgIMA7KA7p6AAPga9+nC6ZaZAcwASE5O9kcZqgk1NTWsXr2aXbt2sWPHDqvLUTbjcwiISDTwJnCXMaa0cauuMcaIyGmPMY0xC4GFABkZGXocGkBVVVW8/PLLvPnmm9TV1VldjrIZn0JARMJwB8Brxpi3PJMPi0i8MaZQROKBIl+LVK1TVVXFv//9b/Lz89m7d68GgDotX64OCPASsNMY80Sjt5YDNwFzPP8u86lC1Wrl5eU8+eSTfPjhh9TU1FhdjrIpX44ERgBTge0iUt/c/Afcv/yZIjId2Adc51uJqqUqKyvJyspi//79HDp0iOrqaqtLUjbmy9WBj4GmunWNbe16le9KSkr44x//SFZWFidPnrS6HGVz2mPwLFJRUUF2djb79u2jsLCQ8vLyFq8jISGBPn364HJZd4PpoEGDCA8Pt2z7TqMhcBY5fPgw99xzD1988QVlZWWtWseYMWN4/PHHCQ217qMRFhamvQXbkIZAEDp+/Di7d+8+pbGvoKCAwsJCSkpKvF5XUlISiYmJDa/79etHTEyM3tLrIBoCQWjbtm3MnDmT48ePf2d6TU0NR48ebdG6Jk+ezF133dXwOjo6WgPAYTQEgkhpaSkFBQXk5ORQUFBAaWlpq9fVo0cPYmNjSU9PJykpyY9VqmCjIRBENmzYwD333MM333zT6nN+cI/gM336dG6++WZiYmL8WKEKRhoCQaCsrIzi4mL27NlDXl4eFRUVrV5XbGwsnTp1Ii0tjfT0dD9WqYKVhkAQ+PDDD3n44YcpLi6msrKy1esJDQ3l9ttvZ+LEiSQkJPixQhXMNARsrLy8nNLSUvbu3Ut2drZPPf86d+5Mhw4d6N27N4MHD/ZjlSrYaQjY2IoVK5g/fz5ff/21T33/IyIiuPvuuxkzZoyeAqhTaAjY2KFDh1i/fn2L7/4TEaKioho6/LRv354hQ4ZwySWXBKJMFeQ0BM5CXbp04YEHHqBfv34AhISEMGjQIIurUnalIWBDNTU1VFdXe90GICJEREQ0DNPdsWNHLrnkEi644IJAlqnOEhoCNrRs2TIyMzP56quvvDoV6NmzJ/fccw/du7tHcmvXrh1paWmBLlOdJTQEbOjLL78kMzPT6/k7duzIlVdeqb/4qlX0gaRKOZyGgM0YY1o0/r+IWHrvvwp+ejpgI8uXL2ft2rVs2LDBq/nPOeccbrnlFlJTU4mNjQ1wdepspSFgE8YY1q5dy5NPPun1MvHx8cyYMYP4+PgAVqbOdhoCQSg1NZVrr72W3r1706FDB6vLUUFOQyAIpaenM3v2bLp06WJ1KeosoCFgsbq6Oj766CO2b9/O5s2brS5HOZCGgMVqa2vJzMzkpZde0icEKUtoCFiktraWdevWsXv3bnbt2qUBoCyjIWCRqqoqXnjhBd58801qa2utLkc5mIZAG6uuriYrK4sDBw6Qn5/fooFCEhMTOf/88znvvPMICwsLYJXKSTQE2lh5eTmPPfYYH3zwQYsfEZaRkcFf//pXOnToQERERIAqVE6jIdDGjDFUVla26BFhiYmJ9OvXj+HDh2sAKL/TEAgCo0aN4oknnqB9+/YaAMrvNARsrEePHqSkpNC/f3+6du1q6fMB1dlLP1U2Nn78eB588EE6dOigAaACRj9ZNhYVFUVCQoLeKqwCyudPl4iEiMgWEVnheX2uiGSJyG4ReUNE9EHzStmYP/7E3AnsbPT6L8CTxph04Bgw3Q/bCHq1tbUcOnSI/Px8nx4jppS/+RQCIpIEXAW86HktwBhgqWeWxcBPfdnG2aKkpITZs2dz44036o1CylZ8bRN4Cvg9UH9TewxQYoypf1xOAZB4ugVFZAYwAyA5OdnHMuyvurqavLw8duzYYXUplikrK+Pbb79tdr7w8HC6dOmibSFtpNUhICI/AYqMMZtEZFRLlzfGLAQWAmRkZHg/qJ4KWkuWLOHll19udr4hQ4bw8MMP07Vr18AXpXw6EhgBXC0iVwKRQEfgaaCziIR6jgaSgIO+l+kskZGRtGvXjnbt2lldil/t37+f9evXNzufy+Xy6eGrqmVafbxljJltjEkyxqQA1wMfGWNuBP4FTPLMdhOwzOcqHebaa6/l9ddf56abbtJDYhVwgegnMAt4XUQeBrYALwVgG0HDGMPJkyepqKjw+pbhtLQ0xo0bF+DKlHLzSwgYY9YCaz3f7wH0IXgeR44cYc6cOXz11Vfk5uZaXY5Sp9AegwF24sQJ1qxZQ3Z2drPzhoSE4HK5CAkJaYPKlHLTELAJEWHSpEmMGzeOYcOGWV2OchANARu58MILmTZtmtVlKIfRpmelHE5DQCmH09MB1WbGjBnj1bgIycnJREVFtUFFCjQEVBsaPXo0o0ePtroM9T0aAgFy9OhRli9fTl5eHkeOHLG6HKWapCEQIIWFhcyZM4fc3FyM0fujlH1pCARQXV1dswEgIowYMYK+ffsycODANqpMqf/SELBYSEgIU6ZMYdq0adpTUFlCQ8BiIkJoaKg+VkxZRvsJKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVweheh8pvKykrq6upOmR4eHu7V2ILKGvo/o/yirKyMxx9/nG3btn1nusvl4uabb+YnP/mJRZWp5mgIqBYxxlBTU3PK9BMnTrBu3TrWrFnznekul4tLLrmE6urqhsesKXvREFAtUlBQwLPPPktRUdF3pp88eZKdO3eeMn9dXR1vvPEGX3zxBRMnTmT8+PFtVarykoaAalbj8/yjR4+SmZlJfn6+18t/9tlnfPbZZ6SkpHDVVVchIohIACpVraEhoM4oJyeHxYsXU15eDrgftf7NN9+0al0rV67k6NGjjBkzhgkTJvizTOUDDQF1Rvn5+SxYsICSkhKf1/Xpp5/y6aefEhYWxtVXX61HAzbhUwiISGfgRWAgYIBpwC7gDSAFyAeuM8Yc86lK1WY2bdrEu+++S21tLQB5eXlUVlZaXJUKJF+PBJ4GVhljJolIONAe+AOwxhgzR0TuA+4DZvm4HdVGtm7dyqOPPkp1dbXVpag20uoQEJFOwA+AmwGMMVVAlYhMAEZ5ZlsMrEVDwHbWrl3Lpk2bTpmelZXVcBSgnMGXI4FzgSPAIhEZAmwC7gS6G2MKPfN8DXT3rUTlb3V1dSxfvpynnnrqlPf0kWnO40sIhALnAb81xmSJyNO4D/0bGGOMiJz2UyUiM4AZ4H4UtQq8uro6Pv74Y3JycsjOztZfeAX4FgIFQIExJsvzeinuEDgsIvHGmEIRiQeKTrewMWYhsBAgIyNDP41toLa2lldffZVFixadto+/cqZWh4Ax5msROSAifYwxu4CxwA7P103AHM+/y/xSqWqx6upqNmzYwNdffw1ATU0Nu3fvPm2335aKjo5mxIgRdOrUCYCqqio2bNjA4cOHm112165dZGZmkpaWxvDhw/VSocV8vTrwW+A1z5WBPcAtuG9PzhSR6cA+4Doft6Fa6cSJEzz22GN8+OGHgPt831+t/t27d+eRRx6hf//+ABw7dowpU6Z4FQKrVq1izZo1TJs2jaFDh+odhhbzae8bY7YCGad5a6wv61XeKSkpYfPmzZw8efK075eVlXHw4EEqKip83laXLl0YOnQokZGRACQkJBAbG0u7du0AqKio8PqXuaamhpqaGvLy8li1ahVJSUkMHjxYby6yiEZwEMvNzeU3v/lNw+H+9xljGrr7+qp3794sWLCA7t3dF3tcLhdRUVE+rfOjjz5iw4YNXHPNNTz33HMNAaPaloZAECopKSEnJ4etW7dSXFzM8ePH/b6N2NhYevfu3fDXedCgQcTGxja0AXxfWFgYAwcO5MSJE+zatYujR482u42qqiqqqqrIz8/nk08+oXv37vTr14+QkBC//izqzDQEgtDWrVv59a9/zZEjR/zSp/90Lr74Yp555pmGw/3w8PAmAwDcDYUPPPAAJSUl3HbbbaxcudLrbW3YsIEbbriBsWPHsmDBAjp27Ohz/cp7GgJBqKqqiqKiIo4d898tGXFxcSQkJDS01Pfp04f4+HgiIiK8Wl5E6NKlC5GRkfTt25eDBw9y4MABr2qsrKyksrKS/fv3k52dTY8ePUhJSdEGwzaie1kBcPXVV3P//fc3hEBUVBTh4eEtXk9kZCSzZ89m5syZzJ49mzfffNPrZTdv3syNN97IhRdeyHPPPUdsbGyLt69aTkMgiJSVlXH48GEOHjzoc//+uLi47xzep6WlkZKS4vM1exEhLi6Ozp07k5aWRnp6OsXFxV6dtlRUVLB//37i4uLIzc2lvLychIQEPSIIMN27QWTDhg3Mnj2b4uJiysrKWr0eEWHatGlMmTKlYVpcXJxfO+2Ehoby29/+lilTpjB37lxeffVVr5fduXMnt9xyCwMHDuSZZ54hISHBb3WpU2kIBIHy8nJKSkrIz89nx44dLb7uX3++Xt/I53K5SE9PZ+DAgYEot2GbSUlJJCQkkJqaSmJiIqWlpXz77bfNLlteXs6uXbsICQnhwIEDhISEEBMTo0cEAaJ7NQisWbOGOXPmUFRU1GTHoDOJiIjg3nvvZcyYMYD7F7StbtpyuVxMnz6dq666igULFrBo0SKvl83Pz+fWW28lPT2duXPnkpqaGsBKnUtDIAgcOXKEzz//vMVdfkWE6OhoOnXqxIABA7jgggsCVOGZJScnk5yczJo1a4iJiaGiosKrTkzl5eVs27aNb7/9lkOHDtG1a1eio6P1iMDPtJ/mWSwqKor777+fv//971x44YVWl8PkyZN54403mDp1aovaHwoLC7n33nuZOXMmeXl5AazQmTRSbay6upqTJ0+2+BRARIiMjKRz585kZGQwatSowBTYQqmpqaSmprJjxw6io6Opqqry6merqKjg008/paCgICC9I51OQ8DGVq1axaJFi9i7d2+Lbv/t3Lkzs2bNYsCAAQwaNCiAFbbOFVdcQc+ePVm9ejULFy7U4cwspiFgQ7W1tdTW1vLVV1+xbNmyZgcAERFCQ0MbDrE7duzIqFGjbHEKcDrp6emkp6fzzTffsHjxYqqqqrwKOWMMVVVVVFdXf+fnVb7RELChd999l7fffpsdO3Z4NQJQYmIid955Z8Mdfu3atSMtLS3QZfrs0ksv5YUXXmD9+vW8+OKLzTZ8Hjt2jEcffZSUlBRuv/32hrEMlG80BGzEGIMxhm3btvHKK694vVznzp2ZOHFiUPziN9arVy969epFeHg4r7zyCjU1NWcc97C8vJyVK1fStWtXJk6cSN++fXUMAj/QPWgj77zzDnfddVeL7sA7GwwbNox58+Zx6623NnRoOpPy8nKee+45Zs2aRXZ2dhtUeHbTIwEbMMZQV1fHunXrmD9/vtXltLn6I4KVK1eyZMmSZntEVlZW8s477zSMczh48OA2qvTspCFgsdraWt555x327NnDJ5980qJle/bsyQ033EBaWhoxMTEBqtC+Tp48yWuvvcaWLVuYOHEiQ4cODdi2qqqqyMzMJCcnp8l5fvCDHzBu3LiA1RAoGgIWq6ur47333uO9995r8bL1DYLx8fEBqMz+qqurWbp0KeHh4aSnpwc8BJYuXcqyZU0Pnl1bW6shoNpGSkoK48ePp3fv3kRHR1tdjt+kpqZyxx13sHv3bpYtW+b1+Ii1tbW8//77DWMtiggjR47koosu8rmmiooKli9fTm5uLrm5uWecNysri3nz5jF06FB++MMfBs8lzPoWaSu/hg8fbs4227dvN+np6Qb305r9+jVu3Dhz9OhRq3/EgKirqzP/+c9/TPfu3Vu8X0Sk4euRRx7xSz3FxcVm9OjR9U/S8qqGmTNnmpqaGr9s35+AjeY0v396JBBEUlJSGD169HeG/j7biAjx8fFMnTqVvXv38s9//tPrsRNMo8uLLX3CUnFxMatXrz7lVucTJ05w8OBBrx/ZVv+LFUw0BILIsGHDeOqpp4iKijqrR+RNT09nzpw5bN26lY0bN/o0gIq3Dhw4wAMPPMD+/fu/M914rtyczTQEgkBqairnn38+F110EZGRkWd1ANQLCQkhNjaWCRMmsGfPHtatW9eim4e2b9/OkiVL6N+/P0OGDDnl/UOHDrF+/fqGXop79+6ltLTUL49oCzYaAkHg0ksvZf78+URGRhIWFmZ1OW0mOTmZuXPnkpuby89+9rMWhcBbb73F8uXLufvuuxk8ePApjXTZ2dncdtttlJaWAu7TB389oi3YaAjYWEpKCv369WPYsGG0b9/eEUcAjYkIERERdO3aldGjRxMfH8/mzZu9CoP6R53l5OTw3nvvndK9+PPPP6esrIzKykqf6+zTp893Rj0aMGBA8FwZQEPA1q644goeeeQRx5wCNKVHjx7MnTuXAwcOMHXqVDZt2uT1sitWrGh4IGtj1dXVfntE2+TJk/nd737X8DoiIiKo7mnQELCxiIgIOnXq5LcPlDGG3NzcJp9d2FhcXBx9+vSxxYfZ5XIRHR1NbGwsGRkZhIWFkZOT49Uw5q0ZlMVb6enpJCQk0KtXrzM+ncnuNAQcpKamhueff55//OMfzc47fvx4nn32WVtdioyJieHPf/4zRUVF/PKXv+Tjjz+2rJb6AVSnTZsW9B22NAQc5vjx4xQVFTU73759+9iyZQvdunUjJSXFFqcjLpeLLl264HK5GDBgAKWlpezbt69NhhxzuVykpKQ0PCcxJCSE1NRUunXrFvBtB5qGgDqt9evXM3nyZEaPHs38+fNt9ZDQDh068Kc//YmjR49y1113sXr16oBvs127dsyePZsf/ehHwH+f5XA20BCwoZiYGGJiYujWrZtlrczl5eWUl5dz+PBh23WWcblcdOvWjejo6IZHnRUVFTVc7vOH0NBQEhISGk6H2rdvz7nnnss555zjt23YhU8hICL/A/wSd7/p7cAtQDzwOhADbAKmGmOqfKzTUa677jpuv/12YmJigupSU1uLjIzkD3/4A7feeisPPvggy5cv99u6Y2NjmTdvXsNTmkJCQkhMTPTb+u2k1SEgIonAHUB/Y0yFiGQC1wNXAk8aY14XkQXAdOB5v1TrEHFxcTp+nhdcLhdJSUl0796d1NRUkpKSKCkp8aqbcWRkJDExMU1e/YiPj6dv376O+H/w9XQgFGgnItVAe6AQGAPc4Hl/MfD/0BBQARQaGsodd9zB9ddfzxNPPEFmZmazywwfPpyHH36YqKio074fERFBenq6v0u1pVaHgDHmoIg8BuwHKoDVuA//S4wx9R2wC4DTHkOJyAxgBtBmz8VT3gsPD6dDhw506tTJ9qckItJwvl4/4nJT6n+unj17Mnz4cDp06NBGVdqXL6cDXYAJwLlACfB/wOXeLm+MWQgsBMjIyAiuey8d4OKLL+a+++4jISGhyb+WwWjEiBHMmjWLhIQE2rdvb3U5tuDL6cAPgb3GmCMAIvIWMALoLCKhnqOBJOCg72UGj7q6OsrLyzlx4kSLW9UjIiIIDw8P6E1CkZGRXnVuSU5O5rLLLvNq9F87iYiIOOPPl5KSwmWXXWarTlBW8yUE9gMXiUh73KcDY4GNwL+ASbivENwEND0o21lo9+7dzJkzh/z8fA4fPuz1ciLCDTfcwE9/+lP69OkTkNpCQ0OZMWMGP/7xj5udNzExkfDw8IDUESgul4tf/OIXjBw5ssl5kpKSgu7nCjRf2gSyRGQpsBmoAbbgPrx/D3hdRB72THvJH4XanTGG6upqDh8+zKpVqygsLGzxOgYNGsTVV18dgOrcRIShQ4cGdEBOqw0aNMiWz1+0M5+uDhhjHgIe+t7kPcAFvqw3GH355Zc8++yz7Nu3z6sbW5SyC+0x6Ad1dXUcPHiQzMxMjh071uLlRYSQkBDbt8Krs5OGgI+2bdvG4sWLycvLa9X96S6Xi8mTJzNy5EhGjBgRgAqVOjMNAR/l5eWxcOFCTpw40arlQ0JCGDt2LNOnT/dzZUp5R0OglTZv3szbb7/Nl19+SVVVy2+NCAsLY9KkSQwZMoSMjIwAVKiUdzQEWmn79u385S9/afXglKGhoVxzzTVMmjTJz5Up1TIaAq00aNAgfv/731NbW9uq5cPCwgLWH0CpltAQaKXzzjuP8847z+oylPKZ9aNIKqUspSGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVwGgJKOZyGgFIO12wIiMjfRKRIRL5oNK2riHwgIrmef7t4pouIPCMiu0UkW0T0ET1K2Zw3RwIvA5d/b9p9wBpjTC9gjec1wBVAL8/XDOB5/5SplAqUZkPAGPMf4JvvTZ4ALPZ8vxj4aaPprxi3T4HOIhLvr2KVUv7X2jaB7saYQs/3XwPdPd8nAgcazVfgmXYKEZkhIhtFZOORI0daWYZSylc+NwwaYwxgWrHcQmNMhjEmIy4uztcylFKt1NoQOFx/mO/5t8gz/SDQs9F8SZ5pSimbam0ILAdu8nx/E7Cs0fRfeK4SXAQcb3TaoJSyodDmZhCRJcAoIFZECoCHgDlApohMB/YB13lmfx+4EtgNlAO3BKBmpZQfNRsCxpifN/HW2NPMa4DbfC1KKdV2tMegUg6nIaCUw2kIKOVwGgJKOZy42/IsLkLkCHACKLa6Fi/EYv86tUb/CYY6va3xHGPMKT3zbBECACKy0RiTYXUdzQmGOrVG/wmGOn2tUU8HlHI4DQGlHM5OIbDQ6gK8FAx1ao3+Ewx1+lSjbdoElFLWsNORgFLKAhoCSjmcLUJARC4XkV2eAUrva36JwBORniLyLxHZISJfisidnumnHWTV4lpDRGSLiKzwvD5XRLI8+/MNEQm3QY2dRWSpiOSIyE4Rudhu+1JE/sfzf/2FiCwRkUg77MtAD/ZreQiISAjwv7gHKe0P/FxE+ltbFQA1wN3GmP7ARcBtnrqaGmTVSncCOxu9/gvwpDEmHTgGTLekqu96GlhljOkLDMFdr232pYgkAncAGcaYgUAIcD322JcvE8jBfo0xln4BFwP/bPR6NjDb6rpOU+cy4EfALiDeMy0e2GVxXUmeD8EYYAUguHuPhZ5u/1pUYydgL56G6EbTbbMv+e/4mF1x32K/AvixXfYlkAJ80dy+A14Afn66+Zr6svxIgBYMTmoVEUkBhgFZND3IqlWeAn4P1HlexwAlxpgaz2s77M9zgSPAIs9py4siEoWN9qUx5iDwGLAfKASOA5uw376s5/Ngv/XsEAK2JiLRwJvAXcaY0sbvGXfUWnaNVUR+AhQZYzZZVYOXQoHzgOeNMcNw3yfynUN/G+zLLriHzD8XSACiOPUQ3JZ83Xd2CAHbDk4qImG4A+A1Y8xbnslNDbJqhRHA1SKSD7yO+5TgadzPe6gfNcoO+7MAKDDGZHleL8UdCnbalz8E9hpjjhhjqoG3cO9fu+3Len4b7NcOIfA50MvTChuOuzFmucU1ISICvATsNMY80eitpgZZbXPGmNnGmCRjTAru/faRMeZG4F/AJM9sltYIYIz5GjggIn08k8YCO7DRvsR9GnCRiLT3/N/X12irfdmI/wb7taoh5nuNHlcCXwF5wP1W1+OpaSTuQ6xsYKvn60rc59xrgFzgQ6Cr1bV66h0FrPB8nwp8hnvA1/8DImxQ31Bgo2d/vgN0sdu+BP4I5ABfAH8HIuywL4EluNspqnEfVU1vat/hbhj+X8/v0nbcVzvOuH7tNqyUw9nhdEApZSENAaUcTkNAKYfTEFDK4cVal40AAAAUSURBVDQElHI4DQGlHE5DQCmH+/+ya0syOHa8bgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zS1YNpuKmMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc562520-d6ff-4174-bb5e-e4be2b16a964"
      },
      "source": [
        "len(data_loader)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUE_WD3mKmMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets build the CNN now."
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlBvXRcQKmMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class one_hot_network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.block=nn.Sequential(\n",
        "            nn.Conv2d(1,32,(7,7),stride=2), # outputs 50x50 image\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32,32,(3,3),stride=1,padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32,32,(3,3),stride=1,padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32,64,(3,3),stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64,64,(3,3),stride=1,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64,256,(3,3),stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(256,512,(3,3),stride=2), ##\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(512,1024,(3,3),stride=2),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "        self.fc=nn.Sequential(\n",
        "            nn.Linear(1024*2*2,300)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        bsize=x.size(0)\n",
        "        x=self.block(x)\n",
        "        x=x.view(bsize,-1)\n",
        "        x=self.fc(x)\n",
        "        return F.sigmoid(x)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx1Nz10Oyx8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net=one_hot_network().to(device)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq_CHBag6lnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "b47a145e-504f-4670-b297-84343d600d6a"
      },
      "source": [
        "summary(net,(1,105,105))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 50, 50]           1,600\n",
            "       BatchNorm2d-2           [-1, 32, 50, 50]              64\n",
            "              ReLU-3           [-1, 32, 50, 50]               0\n",
            "            Conv2d-4           [-1, 32, 50, 50]           9,248\n",
            "       BatchNorm2d-5           [-1, 32, 50, 50]              64\n",
            "              ReLU-6           [-1, 32, 50, 50]               0\n",
            "            Conv2d-7           [-1, 32, 50, 50]           9,248\n",
            "       BatchNorm2d-8           [-1, 32, 50, 50]              64\n",
            "              ReLU-9           [-1, 32, 50, 50]               0\n",
            "           Conv2d-10           [-1, 64, 24, 24]          18,496\n",
            "      BatchNorm2d-11           [-1, 64, 24, 24]             128\n",
            "             ReLU-12           [-1, 64, 24, 24]               0\n",
            "           Conv2d-13           [-1, 64, 24, 24]          36,928\n",
            "      BatchNorm2d-14           [-1, 64, 24, 24]             128\n",
            "             ReLU-15           [-1, 64, 24, 24]               0\n",
            "           Conv2d-16          [-1, 256, 11, 11]         147,712\n",
            "      BatchNorm2d-17          [-1, 256, 11, 11]             512\n",
            "             ReLU-18          [-1, 256, 11, 11]               0\n",
            "           Conv2d-19            [-1, 512, 5, 5]       1,180,160\n",
            "      BatchNorm2d-20            [-1, 512, 5, 5]           1,024\n",
            "             ReLU-21            [-1, 512, 5, 5]               0\n",
            "           Conv2d-22           [-1, 1024, 2, 2]       4,719,616\n",
            "      BatchNorm2d-23           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-24           [-1, 1024, 2, 2]               0\n",
            "           Linear-25                  [-1, 300]       1,229,100\n",
            "================================================================\n",
            "Total params: 7,356,140\n",
            "Trainable params: 7,356,140\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.04\n",
            "Forward/backward pass size (MB): 8.28\n",
            "Params size (MB): 28.06\n",
            "Estimated Total Size (MB): 36.38\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EueISnrH6w3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs=100"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEDFimgb8rFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader=DataLoader(dataset,batch_size=32)\n",
        "criterion=nn.MSELoss()\n",
        "opt=optim.Adam(net.parameters(),lr=1e-5)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQjLqqCh_3TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZlAj9gx8ZvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "outputId": "f962e442-f85d-4754-9c23-bddb80d9d2c6"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    running_loss=.0\n",
        "    for i,data in enumerate(data_loader):\n",
        "        data,target=data[0].to(device),data[1].to(device)\n",
        "        out=net(data)\n",
        "        loss=criterion(out,target)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        running_loss+=loss.item()\n",
        "    print(\"[%d/%d]  running_loss=%.3f\"%(epoch+1,num_epochs,running_loss))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/100]  running_loss=13.242\n",
            "[2/100]  running_loss=4.932\n",
            "[3/100]  running_loss=4.932\n",
            "[4/100]  running_loss=4.932\n",
            "[5/100]  running_loss=4.932\n",
            "[6/100]  running_loss=4.932\n",
            "[7/100]  running_loss=4.932\n",
            "[8/100]  running_loss=4.932\n",
            "[9/100]  running_loss=4.932\n",
            "[10/100]  running_loss=4.932\n",
            "[11/100]  running_loss=4.932\n",
            "[12/100]  running_loss=4.932\n",
            "[13/100]  running_loss=4.932\n",
            "[14/100]  running_loss=4.932\n",
            "[15/100]  running_loss=4.932\n",
            "[16/100]  running_loss=4.932\n",
            "[17/100]  running_loss=4.932\n",
            "[18/100]  running_loss=4.932\n",
            "[19/100]  running_loss=4.932\n",
            "[20/100]  running_loss=4.932\n",
            "[21/100]  running_loss=4.932\n",
            "[22/100]  running_loss=4.932\n",
            "[23/100]  running_loss=4.932\n",
            "[24/100]  running_loss=4.932\n",
            "[25/100]  running_loss=4.932\n",
            "[26/100]  running_loss=4.932\n",
            "[27/100]  running_loss=4.932\n",
            "[28/100]  running_loss=4.932\n",
            "[29/100]  running_loss=4.932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-b4d5f9efb4f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NPuUuJ4_0k7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_chr_vector(chr):\n",
        "    \"\"\"\n",
        "    Function to evaluate the one-hot vector of given chr index.\n",
        "    Args:\n",
        "        chr (int): Index of character you want to test. Must be lesser than 19280.\n",
        "    \"\"\"\n",
        "    dataset=OneHotDataset(data=spline_prims,images=images,labels=labels,oh_len=300)\n",
        "    d_loader=DataLoader(dataset,batch_size=1)\n",
        "\n",
        "    for i,data in enumerate(d_loader):\n",
        "        if i==chr:\n",
        "            og_vec=data[1]\n",
        "            d_vec=net(data[0].to(device))\n",
        "            # print(which_cluster(og_vec.squeeze()),which_cluster(d_vec.squeeze()))\n",
        "            return (which_cluster(og_vec.squeeze()),which_cluster(d_vec.squeeze()))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-6kkXUACV7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cb95e6d-8b69-4d85-b9ea-23ac9133bed2"
      },
      "source": [
        "eval_chr_vector(1928)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([128], [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joH8orM6Dg-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}