{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "one_hot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eacc9cc89bb74d46bb2cb61e1100d272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cc135c1b02df4c40a55a1e1082ff01ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3237227854f474c8abf7e22220e3cba",
              "IPY_MODEL_d33fc6a5dbc84453bdcebba1647a8478"
            ]
          }
        },
        "cc135c1b02df4c40a55a1e1082ff01ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3237227854f474c8abf7e22220e3cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bae564e41610413db422b77d6d7c2d1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e120f7882ea483785301b59500fa28f"
          }
        },
        "d33fc6a5dbc84453bdcebba1647a8478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c1ab17187b54296874d97e16cf865fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48762/? [00:32&lt;00:00, 1487.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff47921b963a4797bcdae65fc6fc7643"
          }
        },
        "bae564e41610413db422b77d6d7c2d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e120f7882ea483785301b59500fa28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c1ab17187b54296874d97e16cf865fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff47921b963a4797bcdae65fc6fc7643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomTambe/omniglot-bcs/blob/master/one_hot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQjLqqCh_3TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta4g8aPfKo1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfe73e59-0444-4643-a7bb-8f16166921df"
      },
      "source": [
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/splines.py\n",
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/encoded.py\n",
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/weights/2-d/decoder.pth\n",
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/weights/2-d/encoder.pth\n",
        "!wget https://github.com/SomTambe/omniglot-bcs/raw/master/data_background.mat\n",
        "# !wget https://github.com/SomTambe/omniglot-bcs/raw/master/weights/one-hot/one_hot_wgts.pth"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-12 10:52:52--  https://github.com/SomTambe/omniglot-bcs/raw/master/splines.py\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/splines.py [following]\n",
            "--2020-07-12 10:52:52--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/splines.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4642 (4.5K) [text/plain]\n",
            "Saving to: â€˜splines.pyâ€™\n",
            "\n",
            "\rsplines.py            0%[                    ]       0  --.-KB/s               \rsplines.py          100%[===================>]   4.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-12 10:52:52 (40.8 MB/s) - â€˜splines.pyâ€™ saved [4642/4642]\n",
            "\n",
            "--2020-07-12 10:52:55--  https://github.com/SomTambe/omniglot-bcs/raw/master/encoded.py\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/encoded.py [following]\n",
            "--2020-07-12 10:52:56--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/encoded.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4214 (4.1K) [text/plain]\n",
            "Saving to: â€˜encoded.pyâ€™\n",
            "\n",
            "encoded.py          100%[===================>]   4.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-12 10:52:56 (62.8 MB/s) - â€˜encoded.pyâ€™ saved [4214/4214]\n",
            "\n",
            "--2020-07-12 10:53:02--  https://github.com/SomTambe/omniglot-bcs/raw/master/weights/2-d/decoder.pth\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/weights/2-d/decoder.pth [following]\n",
            "--2020-07-12 10:53:02--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/weights/2-d/decoder.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4217359 (4.0M) [application/octet-stream]\n",
            "Saving to: â€˜decoder.pthâ€™\n",
            "\n",
            "decoder.pth         100%[===================>]   4.02M  15.5MB/s    in 0.3s    \n",
            "\n",
            "2020-07-12 10:53:03 (15.5 MB/s) - â€˜decoder.pthâ€™ saved [4217359/4217359]\n",
            "\n",
            "--2020-07-12 10:53:07--  https://github.com/SomTambe/omniglot-bcs/raw/master/weights/2-d/encoder.pth\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/weights/2-d/encoder.pth [following]\n",
            "--2020-07-12 10:53:08--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/weights/2-d/encoder.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4225740 (4.0M) [application/octet-stream]\n",
            "Saving to: â€˜encoder.pthâ€™\n",
            "\n",
            "encoder.pth         100%[===================>]   4.03M  13.1MB/s    in 0.3s    \n",
            "\n",
            "2020-07-12 10:53:09 (13.1 MB/s) - â€˜encoder.pthâ€™ saved [4225740/4225740]\n",
            "\n",
            "--2020-07-12 10:53:11--  https://github.com/SomTambe/omniglot-bcs/raw/master/data_background.mat\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/data_background.mat [following]\n",
            "--2020-07-12 10:53:12--  https://raw.githubusercontent.com/SomTambe/omniglot-bcs/master/data_background.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21514095 (21M) [application/octet-stream]\n",
            "Saving to: â€˜data_background.matâ€™\n",
            "\n",
            "data_background.mat 100%[===================>]  20.52M  37.9MB/s    in 0.5s    \n",
            "\n",
            "2020-07-12 10:53:13 (37.9 MB/s) - â€˜data_background.matâ€™ saved [21514095/21514095]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F5qy4nhKmK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "57e30caf-60ff-4cbc-95f1-4e52a0527851"
      },
      "source": [
        "import splines\n",
        "import torch\n",
        "import glob\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import scipy\n",
        "from tqdm.notebook import tqdm\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import encoded\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 12 10:53:21 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG63K2uxKmLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4300f48d-a8c2-4715-9f0e-d737ec557c10"
      },
      "source": [
        "device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NntTEbdlKmLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "back_dict=splines.mat_to_dict()\n",
        "spline_prims=splines.spline_dict(back_dict)\n",
        "images=splines.dict_images()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb8gz-24KmLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83978d1b-71c9-47d1-cb56-ae34459b522b"
      },
      "source": [
        "dataset=encoded.OmniglotData(spline_prims)\n",
        "data_loader=DataLoader(dataset,batch_size=1,shuffle=False) # Using batchsize 1 to get single primitive at a time.\n",
        "# Create instances of models\n",
        "enc=encoded.encoder(latent_dim=2).to(device)\n",
        "dec=encoded.decoder(latent_dim=2).to(device)\n",
        "# Loading weights\n",
        "# enc.load_state_dict(torch.load('./weights/2-d/encoder.pth',map_location=torch.device('cpu')))\n",
        "# dec.load_state_dict(torch.load('./weights/2-d/decoder.pth',map_location=torch.device('cpu')))\n",
        "enc.load_state_dict(torch.load('encoder.pth'))\n",
        "dec.load_state_dict(torch.load('decoder.pth'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U889d28aKmLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "eacc9cc89bb74d46bb2cb61e1100d272",
            "cc135c1b02df4c40a55a1e1082ff01ab",
            "d3237227854f474c8abf7e22220e3cba",
            "d33fc6a5dbc84453bdcebba1647a8478",
            "bae564e41610413db422b77d6d7c2d1a",
            "4e120f7882ea483785301b59500fa28f",
            "6c1ab17187b54296874d97e16cf865fd",
            "ff47921b963a4797bcdae65fc6fc7643"
          ]
        },
        "outputId": "eadb11bc-0873-477d-9d1a-7ae6e9e053d5"
      },
      "source": [
        "x_2d=[]\n",
        "y_2d=[]\n",
        "for i,data in tqdm(enumerate(data_loader)):\n",
        "    data=data.to(device)\n",
        "    mu,var=enc(data)\n",
        "    lat_var=encoded.gen_latent(mu,var).squeeze().detach().cpu().numpy()\n",
        "    x_2d.append(lat_var[0].item());y_2d.append(lat_var[1].item())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eacc9cc89bb74d46bb2cb61e1100d272",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n3JTfVOKmLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dfcf74b-8c5c-40a3-f470-730be40d579a"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import time\n",
        "start=time.time()\n",
        "X=np.concatenate((np.reshape(x_2d,(-1,1)),np.reshape(y_2d,(-1,1))),axis=1)\n",
        "kmeans = KMeans(300, random_state=0)\n",
        "labels = kmeans.fit(X).predict(X)\n",
        "print(\"%d\"%(time.time()-start))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te8zaFAwKmLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f9d87462-e606-4f0a-fc80-ca39dc74eb3f"
      },
      "source": [
        "print(len(labels))\n",
        "print('max: ',np.max(labels,0))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48762\n",
            "max:  299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozNNfNh5KmL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us now prepare the dataloader for the next model, for performing \n",
        "# supervised learning using the one-hot encoded vectors of a particular character.\n",
        "\n",
        "class OneHotDataset(IterableDataset):\n",
        "    \"\"\"\n",
        "    Iterable form dataset for providing one-hot encoded vectors for each character.\n",
        "    \n",
        "    Args:\n",
        "        data (dict): Just pass the spline_prims variable.\n",
        "        images (dict): Just pass the image dict.\n",
        "        labels (iterable type object): Labels for clustered data.\n",
        "        \n",
        "    Returns:\n",
        "        (Tensor) : One-hot encoded vector of length 300. (image,target)\n",
        "    \"\"\"\n",
        "    def __init__(self,data,images,labels,oh_len,transform=None):\n",
        "        self.data=data\n",
        "        self.images=images\n",
        "        self.labels=labels\n",
        "        self.oh_len=oh_len\n",
        "        self.transform=transform\n",
        "\n",
        "    def _apply_transform(self,x):\n",
        "        if self.transform is not None:\n",
        "            return self.transform(x)\n",
        "        else :\n",
        "            return x\n",
        "    \n",
        "    def stream(self):\n",
        "        # spline_prims[lang][char][inst][0][primitive]\n",
        "        # images[lang][char][0]['image'][inst][0] -> (105,105) numpy ndarray\n",
        "        count=0\n",
        "        for lang in self.data:\n",
        "            for i,char in enumerate(self.data[lang]):\n",
        "                for j,inst in enumerate(char):\n",
        "                    vector=np.zeros((self.oh_len))\n",
        "                    for prim in inst[0]:\n",
        "                        # yield torch.tensor(prim.reshape(-1)).float()\n",
        "                        # yield torch.tensor(self.normalize(prim).reshape(-1)).float()\n",
        "                        idx=self.labels[count]\n",
        "                        # vector[idx]+=1.\n",
        "                        if vector[idx]==0:\n",
        "                            vector[idx]+=1.\n",
        "                        count+=1\n",
        "                    # yield [image,vector]\n",
        "                    img=self.images[lang][i][0]['image'][j][0]\n",
        "                    img=self._apply_transform(img)\n",
        "                    img=img.float()\n",
        "\n",
        "                    vector=torch.tensor(vector).float()\n",
        "                    yield [img,vector]\n",
        "                    \n",
        "    def __len__(self):\n",
        "        return int(19280) # Literally meaningless, hardcoded\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self.stream()\n",
        "        "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5vDui4kKmL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def which_cluster(vector):\n",
        "    \"\"\"\n",
        "    Dummy function to just give the indices of the clusters.\n",
        "    \n",
        "    Arg:\n",
        "        vector: You know what it is.\n",
        "    \"\"\"\n",
        "    vector=vector.reshape(-1)\n",
        "    which=[]\n",
        "    idx=0\n",
        "    for _ in vector:\n",
        "        # if vector[idx]==1:\n",
        "        #     which.append(idx)\n",
        "        # if vector[idx]>1:\n",
        "        #     which.append('{0},special'.format(idx))\n",
        "        if vector[idx]>0:\n",
        "            which.append(idx)\n",
        "        idx+=1\n",
        "    return which"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAB3pPVTKmMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform=transforms.Compose([\n",
        "                              transforms.ToPILImage(),\n",
        "                              transforms.Resize((28,28)),\n",
        "                              transforms.ToTensor(),\n",
        "])\n",
        "dataset=OneHotDataset(data=spline_prims,images=images,labels=labels,oh_len=300,transform=transform)\n",
        "data_loader=DataLoader(dataset,batch_size=1)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJSrvMwKmMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "66954206-8f87-404c-f657-4a307d225796"
      },
      "source": [
        "plot=12844\n",
        "for k,i in enumerate(data_loader):\n",
        "    # print(i[0].shape,i[1].shape)\n",
        "    if plot==k:\n",
        "        # print(which_cluster(i[1]))\n",
        "        plt.imshow(i[0].squeeze().detach().cpu().numpy(),cmap='gray_r')\n",
        "        break\n",
        "#     print(type(i[0]),type(i[1]))\n",
        "#     print(which_cluster(i[1]))\n",
        "plt.show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zS1YNpuKmMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "273676b0-999a-43cc-e587-b52e61cc33ac"
      },
      "source": [
        "len(data_loader)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUE_WD3mKmMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets build the CNN now."
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlBvXRcQKmMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class one_hot_network(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.block=nn.Sequential(\n",
        "#             nn.Conv2d(1,32,(7,7),stride=2), # outputs 50x50 image\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.ReLU(True),\n",
        "#             nn.Conv2d(32,32,(3,3),stride=1,padding=1),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.ReLU(True),\n",
        "#             nn.Conv2d(32,32,(3,3),stride=1,padding=1),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.ReLU(True),\n",
        "#             nn.Conv2d(32,64,(3,3),stride=2),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(True),\n",
        "#             nn.Conv2d(64,64,(3,3),stride=1,padding=1),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(True),\n",
        "#             nn.Conv2d(64,256,(3,3),stride=2),\n",
        "#             nn.BatchNorm2d(256),\n",
        "#             nn.ReLU(True),\n",
        "#             nn.Conv2d(256,512,(3,3),stride=2), ##\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(True),\n",
        "#             nn.Conv2d(512,1024,(3,3),stride=2),\n",
        "#             nn.BatchNorm2d(1024),\n",
        "#             nn.ReLU(True),\n",
        "#         )\n",
        "#         self.fc=nn.Sequential(\n",
        "#             nn.Linear(1024*2*2,300)\n",
        "#         )\n",
        "\n",
        "#     def forward(self,x):\n",
        "#         bsize=x.size(0)\n",
        "#         x=self.block(x)\n",
        "#         x=x.view(bsize,-1)\n",
        "#         x=self.fc(x)\n",
        "#         return F.sigmoid(x)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHyn3BhYweGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class one_hot_network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv=nn.Sequential(\n",
        "            nn.Conv2d(1,128,(3,3),1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(128,128,(3,3),1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(128,128,(3,3),1),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.pool=nn.MaxPool2d((2,2),stride=2)\n",
        "        self.fc=nn.Sequential(\n",
        "            nn.Linear(11*11*(128),3000),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(3000,300)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        bsize=x.size(0)\n",
        "        x=self.conv(x)\n",
        "        x=self.pool(x)\n",
        "        x=x.view(bsize,-1)\n",
        "        x=self.fc(x)\n",
        "        return F.sigmoid(x)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx1Nz10Oyx8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net=one_hot_network().to(device)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq_CHBag6lnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "71186070-ede0-4c56-e9ef-2b8fd6bc7d39"
      },
      "source": [
        "summary(net,(1,28,28))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 26, 26]           1,280\n",
            "              ReLU-2          [-1, 128, 26, 26]               0\n",
            "            Conv2d-3          [-1, 128, 24, 24]         147,584\n",
            "              ReLU-4          [-1, 128, 24, 24]               0\n",
            "            Conv2d-5          [-1, 128, 22, 22]         147,584\n",
            "              ReLU-6          [-1, 128, 22, 22]               0\n",
            "         MaxPool2d-7          [-1, 128, 11, 11]               0\n",
            "            Linear-8                 [-1, 3000]      46,467,000\n",
            "              ReLU-9                 [-1, 3000]               0\n",
            "           Linear-10                  [-1, 300]         900,300\n",
            "================================================================\n",
            "Total params: 47,663,748\n",
            "Trainable params: 47,663,748\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.56\n",
            "Params size (MB): 181.82\n",
            "Estimated Total Size (MB): 185.38\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EueISnrH6w3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs=100"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEDFimgb8rFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader=DataLoader(dataset,batch_size=32)\n",
        "criterion=nn.BCELoss()\n",
        "opt=optim.Adam(net.parameters(),lr=5e-4)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZlAj9gx8ZvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "5cabab99-a89b-4c1c-d813-0f9c2c2a97a7"
      },
      "source": [
        "net.train()\n",
        "losses=[]\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss=.0\n",
        "    for i,data in enumerate(data_loader):\n",
        "        data,target=data[0].to(device),data[1].to(device)\n",
        "        out=net(data)\n",
        "        loss=criterion(out,target)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        running_loss+=loss.item()\n",
        "    losses.append(running_loss)\n",
        "    print(\"[%d/%d]  running_loss=%.3f\"%(epoch+1,num_epochs,running_loss))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/100]  running_loss=3843.807\n",
            "[2/100]  running_loss=3991.396\n",
            "[3/100]  running_loss=3991.396\n",
            "[4/100]  running_loss=3991.396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-0c0da4769310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrunning_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-cf4bc9606b13>\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;31m# yield [image,vector]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-cf4bc9606b13>\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9mDEhCv2aTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1a1cffa0-ce7b-431f-f555-65439e4276c9"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NPuUuJ4_0k7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_chr_vector(chr):\n",
        "    \"\"\"\n",
        "    Function to evaluate the one-hot vector of given chr index.\n",
        "    Args:\n",
        "        chr (int): Index of character you want to test. Must be lesser than 19280.\n",
        "    \"\"\"\n",
        "    dataset=OneHotDataset(data=spline_prims,images=images,labels=labels,oh_len=300)\n",
        "    d_loader=DataLoader(dataset,batch_size=1)\n",
        "\n",
        "    for i,data in enumerate(d_loader):\n",
        "        if i==chr:\n",
        "            og_vec=data[1]\n",
        "            d_vec=net(data[0].to(device))\n",
        "            print(which_cluster(og_vec.squeeze()))\n",
        "            # return (og_vec.squeeze()[which_cluster(og_vec.squeeze())],d_vec.squeeze()[which_cluster(og_vec.squeeze())])\n",
        "            return (og_vec.squeeze(),d_vec.squeeze())\n",
        "            # return (which_cluster(og_vec.squeeze()),which_cluster(d_vec.squeeze()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JJtmnYIMd5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM=1988"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfOmnro4Sv2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aab82558-553d-42a3-974f-a70fb09f6771"
      },
      "source": [
        "eval_chr_vector(NUM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[27]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " tensor([2.8856e-02, 2.4905e-02, 3.9314e-03, 7.2832e-03, 4.1272e-03, 1.8907e-02,\n",
              "         9.6762e-04, 5.3425e-03, 1.3643e-02, 7.1297e-03, 1.4632e-02, 1.6559e-03,\n",
              "         2.2600e-02, 2.4238e-08, 1.3302e-02, 8.5326e-03, 1.5317e-02, 2.8744e-14,\n",
              "         2.3111e-03, 4.3074e-03, 7.3267e-03, 2.9433e-14, 1.5826e-02, 4.0611e-03,\n",
              "         3.4638e-03, 2.0279e-03, 9.4591e-03, 6.5223e-03, 2.9056e-14, 3.7948e-04,\n",
              "         7.2510e-03, 2.5874e-03, 2.3487e-03, 3.1194e-03, 1.8268e-02, 2.0851e-02,\n",
              "         1.0176e-02, 6.2345e-03, 2.4178e-03, 1.6071e-03, 1.8775e-02, 1.9163e-02,\n",
              "         4.5624e-03, 9.6966e-03, 8.4435e-03, 2.9329e-03, 6.8214e-03, 8.9947e-03,\n",
              "         5.4453e-03, 1.0018e-02, 1.4065e-02, 5.2890e-03, 2.7115e-03, 7.6479e-03,\n",
              "         1.0768e-03, 1.6717e-02, 2.4312e-02, 2.8274e-14, 7.8490e-03, 5.2248e-03,\n",
              "         1.6246e-03, 2.1243e-03, 4.2860e-03, 3.9043e-03, 2.8922e-03, 1.3255e-03,\n",
              "         1.5148e-02, 1.6473e-02, 3.4560e-03, 3.7649e-03, 2.5104e-03, 4.0921e-04,\n",
              "         4.0000e-03, 2.3054e-02, 9.5692e-03, 5.6460e-03, 2.9974e-14, 4.7306e-03,\n",
              "         2.6168e-02, 1.5477e-02, 2.4644e-10, 2.6533e-02, 2.8864e-03, 6.9445e-03,\n",
              "         1.0708e-02, 6.6759e-04, 7.6280e-03, 9.5416e-03, 1.9571e-02, 2.8697e-03,\n",
              "         1.3727e-02, 2.4856e-03, 8.9921e-03, 3.4087e-03, 5.6669e-03, 4.5005e-03,\n",
              "         6.5356e-03, 2.6019e-03, 1.0199e-02, 9.4378e-03, 4.7683e-03, 2.1301e-02,\n",
              "         2.5852e-03, 3.4312e-02, 1.4900e-02, 1.8306e-03, 7.4759e-03, 8.0560e-03,\n",
              "         1.2270e-02, 7.3345e-03, 4.6117e-03, 3.8753e-05, 1.4722e-03, 9.8770e-04,\n",
              "         1.9868e-02, 1.3192e-02, 3.9580e-03, 6.9031e-03, 1.0716e-02, 1.2291e-02,\n",
              "         2.4765e-03, 8.7450e-03, 7.8247e-03, 9.8322e-03, 1.3948e-02, 2.8520e-14,\n",
              "         9.2626e-03, 2.6510e-02, 7.6244e-03, 9.7916e-03, 2.4460e-02, 3.2213e-14,\n",
              "         9.6147e-04, 4.2117e-03, 3.8911e-09, 1.1144e-03, 3.7546e-03, 2.9982e-03,\n",
              "         4.0275e-03, 2.2089e-03, 5.9131e-03, 8.1071e-03, 8.5375e-03, 1.2460e-02,\n",
              "         6.0178e-03, 1.1308e-02, 1.1486e-02, 3.6312e-03, 2.7431e-02, 7.4397e-03,\n",
              "         1.8525e-02, 1.0742e-02, 1.8994e-02, 4.4116e-03, 1.1799e-02, 2.7447e-02,\n",
              "         7.8722e-03, 3.5193e-03, 1.1351e-02, 6.6863e-03, 4.3883e-03, 8.2012e-03,\n",
              "         1.2144e-02, 2.9829e-03, 5.6431e-04, 7.8823e-04, 4.4861e-03, 5.7199e-03,\n",
              "         5.9941e-03, 1.2988e-02, 5.7545e-03, 3.3331e-04, 1.0497e-02, 2.5454e-02,\n",
              "         1.3057e-02, 2.2753e-03, 1.2264e-02, 3.2000e-03, 9.3192e-04, 3.8495e-03,\n",
              "         6.4554e-03, 1.7472e-02, 1.0949e-03, 5.1869e-03, 1.1195e-02, 2.9799e-14,\n",
              "         4.8435e-03, 2.0271e-03, 9.6784e-03, 2.2023e-03, 2.7142e-02, 6.2346e-03,\n",
              "         5.9981e-03, 1.2474e-02, 8.2182e-03, 1.8316e-02, 7.1191e-04, 3.4787e-02,\n",
              "         1.3216e-03, 4.5442e-03, 1.7298e-02, 2.7838e-03, 4.7329e-03, 1.4041e-02,\n",
              "         9.7117e-03, 3.4188e-03, 1.1720e-03, 6.9461e-03, 6.3106e-03, 1.0474e-02,\n",
              "         5.2294e-05, 1.7759e-02, 7.8355e-03, 2.6742e-03, 1.0704e-03, 2.3716e-02,\n",
              "         4.9294e-03, 2.3888e-04, 5.0348e-03, 1.2562e-02, 5.6684e-03, 1.9643e-03,\n",
              "         3.0067e-14, 1.3619e-03, 1.1696e-02, 1.7309e-02, 8.5731e-04, 3.6901e-03,\n",
              "         1.1353e-02, 1.1537e-02, 7.7634e-03, 4.9028e-03, 2.4382e-03, 2.0466e-02,\n",
              "         3.1059e-03, 6.2558e-03, 5.1237e-04, 1.5257e-02, 3.4980e-03, 3.0504e-03,\n",
              "         4.9091e-03, 9.1035e-03, 1.3741e-02, 2.7792e-03, 2.9927e-14, 1.5615e-02,\n",
              "         9.2613e-03, 4.7409e-03, 6.3293e-03, 1.0694e-02, 2.7719e-02, 7.6502e-03,\n",
              "         1.7672e-02, 2.0879e-02, 4.1605e-03, 2.6869e-05, 6.3226e-03, 5.6551e-03,\n",
              "         1.9020e-03, 1.4446e-02, 3.1106e-03, 1.1263e-02, 3.5080e-03, 9.7012e-03,\n",
              "         7.6196e-03, 7.1531e-03, 3.5210e-14, 5.0677e-03, 9.8525e-03, 1.0304e-02,\n",
              "         1.7248e-02, 7.0690e-03, 4.2250e-03, 6.2731e-03, 1.2239e-04, 2.3781e-02,\n",
              "         2.8099e-03, 7.4354e-03, 6.1346e-03, 9.2082e-03, 1.7831e-03, 1.0035e-02,\n",
              "         5.5881e-03, 9.4755e-03, 1.8012e-03, 7.5499e-03, 1.9906e-02, 4.4811e-04,\n",
              "         5.7868e-08, 5.6347e-03, 1.0306e-02, 5.9921e-03, 3.0019e-03, 2.9421e-03,\n",
              "         5.7687e-03, 9.5538e-04, 6.9349e-03, 5.1479e-03, 4.4728e-03, 1.8104e-02],\n",
              "        device='cuda:0', grad_fn=<SqueezeBackward0>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-6kkXUACV7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecb34b08-ca6f-44a5-cf7e-172d77e9ccdf"
      },
      "source": [
        "a,b=eval_chr_vector(NUM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[27]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmwavHBNMTOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6931821f-5a93-4f3c-bb15-bc01079f5a9a"
      },
      "source": [
        "torch.max(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0348, device='cuda:0', grad_fn=<MaxBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M1SpODm1XYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH='./one_hot_wgts.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAZ8idsRUdD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joH8orM6Dg-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9818b1e3-9781-49a0-8d50-c7215a4dea9e"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_238e2a05-4cee-4d92-b9d8-9fb55fa6bccd\", \"one_hot_wgts.pth\", 29449729)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IG0_tr2Uti2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "401c466b-e95a-441b-a927-3dba480cb2c3"
      },
      "source": [
        "net.load_state_dict(torch.load(PATH))\n",
        "net.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "one_hot_network(\n",
              "  (block): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(7, 7), stride=(2, 2))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (23): ReLU(inplace=True)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=300, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yISu9khz1d5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}